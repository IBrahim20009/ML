{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475f9d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "class ChatbotModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(ChatbotModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ChatbotAssistant:\n",
    "    def __init__(self, intents_path, function_mappings=None):\n",
    "        self.model = None\n",
    "        self.intents_path = intents_path\n",
    "        self.documents = []\n",
    "        self.vocabulary = []\n",
    "        self.intents = []\n",
    "        self.intents_responses = {}\n",
    "        self.function_mappings = function_mappings\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    @staticmethod\n",
    "    def tokenize_and_lemmatize(text):\n",
    "        lemmatizer = nltk.WordNetLemmatizer()\n",
    "        words = nltk.word_tokenize(text)\n",
    "        words = [lemmatizer.lemmatize(word.lower()) for word in words]\n",
    "        return words\n",
    "\n",
    "    def bag_of_words(self, words):\n",
    "        return [1 if word in words else 0 for word in self.vocabulary]\n",
    "\n",
    "    def parse_intents(self):\n",
    "        if os.path.exists(self.intents_path):\n",
    "            with open(self.intents_path, 'r') as f:\n",
    "                intents_data = json.load(f)\n",
    "\n",
    "            for intent in intents_data['intents']:\n",
    "                if intent['tag'] not in self.intents:\n",
    "                    self.intents.append(intent['tag'])\n",
    "                    self.intents_responses[intent['tag']] = intent['responses']\n",
    "\n",
    "                for pattern in intent['patterns']:\n",
    "                    pattern_words = self.tokenize_and_lemmatize(pattern)\n",
    "                    self.vocabulary.extend(pattern_words)\n",
    "                    self.documents.append((pattern_words, intent['tag']))\n",
    "\n",
    "            self.vocabulary = sorted(set(self.vocabulary))\n",
    "\n",
    "    def prepare_data(self):\n",
    "        if not self.documents:\n",
    "            raise ValueError(\"No training data found. Make sure to call parse_intents() first.\")\n",
    "\n",
    "        bags = []\n",
    "        indices = []\n",
    "        for document in self.documents:\n",
    "            words = document[0]\n",
    "            bag = self.bag_of_words(words)\n",
    "            intent_index = self.intents.index(document[1])\n",
    "            bags.append(bag)\n",
    "            indices.append(intent_index)\n",
    "\n",
    "        self.X = np.array(bags)\n",
    "        self.y = np.array(indices)\n",
    "\n",
    "    def train_model(self, batch_size, lr, epochs):\n",
    "        if self.X is None or self.y is None or len(self.X) == 0:\n",
    "            raise ValueError(\"Training data is empty. Run prepare_data() first.\")\n",
    "\n",
    "        print(f\"Using device: {self.device}\")\n",
    "\n",
    "        X_tensor = torch.tensor(self.X, dtype=torch.float32).to(self.device)\n",
    "        y_tensor = torch.tensor(self.y, dtype=torch.long).to(self.device)\n",
    "\n",
    "        dataset = TensorDataset(X_tensor, y_tensor)\n",
    "        loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        self.model = ChatbotModel(self.X.shape[1], len(self.intents)).to(self.device)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=lr)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            running_loss = 0.0\n",
    "            for batch_X, batch_y in loader:\n",
    "                batch_X, batch_y = batch_X.to(self.device), batch_y.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(batch_X)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "\n",
    "            print(f\"Epoch {epoch+1}: Loss: {running_loss / len(loader):.4f}\")\n",
    "\n",
    "    def save_model(self, model_path, dimensions_path):\n",
    "        torch.save(self.model.state_dict(), model_path)\n",
    "        with open(dimensions_path, 'w') as f:\n",
    "            json.dump({'input_size': self.X.shape[1], 'output_size': len(self.intents)}, f)\n",
    "\n",
    "    def load_model(self, model_path, dimensions_path):\n",
    "        with open(dimensions_path, 'r') as f:\n",
    "            dimensions = json.load(f)\n",
    "\n",
    "        self.model = ChatbotModel(dimensions['input_size'], dimensions['output_size']).to(self.device)\n",
    "        self.model.load_state_dict(torch.load(model_path, map_location=self.device))\n",
    "\n",
    "    def process_message(self, input_message):\n",
    "        words = self.tokenize_and_lemmatize(input_message)\n",
    "        bag = self.bag_of_words(words)\n",
    "        bag_tensor = torch.tensor([bag], dtype=torch.float32).to(self.device)\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            predictions = self.model(bag_tensor)\n",
    "\n",
    "        predicted_class_index = torch.argmax(predictions, dim=1).item()\n",
    "        predicted_intent = self.intents[predicted_class_index]\n",
    "\n",
    "        if self.function_mappings and predicted_intent in self.function_mappings:\n",
    "            self.function_mappings[predicted_intent]()\n",
    "\n",
    "        if self.intents_responses[predicted_intent]:\n",
    "            return random.choice(self.intents_responses[predicted_intent])\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "\n",
    "def get_stocks():\n",
    "    stocks = ['APPL', 'META', 'NVDA', 'GS', 'MSFT']\n",
    "    print(random.sample(stocks, 3))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    assistant = ChatbotAssistant('intents.json', function_mappings={'stocks': get_stocks})\n",
    "    assistant.parse_intents()\n",
    "    assistant.prepare_data()\n",
    "    assistant.train_model(batch_size=8, lr=0.001, epochs=100)\n",
    "    assistant.save_model('chatbot_model.pth', 'dimensions.json')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TorchConda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
